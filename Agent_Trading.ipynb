{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6adf71e3-d37e-42fd-a667-b7232b3fc39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• T√©l√©chargement des donn√©es en 5 min par batch...\n",
      " - 2025-05-01 -> 2025-05-11\n",
      " - 2025-05-12 -> 2025-05-22\n",
      " - 2025-05-23 -> 2025-06-02\n",
      " - 2025-06-03 -> 2025-06-13\n",
      " - 2025-06-14 -> 2025-06-24\n",
      " - 2025-06-25 -> 2025-07-01\n",
      "‚úÖ Donn√©es t√©l√©charg√©es. Nettoyage...\n",
      "‚úÖ Calcul des indicateurs techniques...\n",
      "‚úÖ Calcul de la target future_close √† 12 bougies...\n",
      "              datetime    close  future_close\n",
      "25 2025-05-01 02:05:00  3239.30       3237.26\n",
      "26 2025-05-01 02:10:00  3240.29       3231.90\n",
      "27 2025-05-01 02:15:00  3245.06       3235.39\n",
      "28 2025-05-01 02:20:00  3250.03       3232.74\n",
      "29 2025-05-01 02:25:00  3246.39       3233.19\n",
      "‚úÖ Donn√©es sauvegard√©es dans gold_features_hourly_future_close.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import ta\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "api_key = 'f5754d3325dc4149ba98663c7dd9821e'\n",
    "symbol = 'XAU/USD'\n",
    "interval = '5min'\n",
    "start_date = '2025-05-01'\n",
    "end_date = '2025-07-01'\n",
    "future_horizon = 12\n",
    "\n",
    "# === T√©l√©chargement d'une page ===\n",
    "def fetch_data_page(start_date, end_date):\n",
    "    url = 'https://api.twelvedata.com/time_series'\n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'apikey': api_key,\n",
    "        'format': 'JSON',\n",
    "        'order': 'ASC',\n",
    "        'timezone': 'UTC',\n",
    "        'outputsize': 5000\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    if 'values' in data:\n",
    "        return pd.DataFrame(data['values'])\n",
    "    else:\n",
    "        print(\"Erreur:\", data)\n",
    "        return None\n",
    "\n",
    "# === Boucle historique ===\n",
    "all_data = pd.DataFrame()\n",
    "current_start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "final_end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "print(\"üì• T√©l√©chargement des donn√©es en 5 min par batch...\")\n",
    "\n",
    "while current_start < final_end:\n",
    "    current_end = current_start + timedelta(days=10)\n",
    "    if current_end > final_end:\n",
    "        current_end = final_end\n",
    "\n",
    "    print(f\" - {current_start.date()} -> {current_end.date()}\")\n",
    "    df_page = fetch_data_page(current_start.strftime(\"%Y-%m-%d\"), current_end.strftime(\"%Y-%m-%d\"))\n",
    "    if df_page is not None and not df_page.empty:\n",
    "        all_data = pd.concat([all_data, df_page])\n",
    "\n",
    "    current_start = current_end + timedelta(days=1)\n",
    "    time.sleep(10)\n",
    "\n",
    "# === Nettoyage ===\n",
    "if all_data.empty:\n",
    "    print(\"‚ùå ERREUR : aucune donn√©e t√©l√©charg√©e.\")\n",
    "    exit()\n",
    "\n",
    "print(\"‚úÖ Donn√©es t√©l√©charg√©es. Nettoyage...\")\n",
    "\n",
    "all_data['datetime'] = pd.to_datetime(all_data['datetime'])\n",
    "all_data = all_data.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "for col in ['open', 'high', 'low', 'close']:\n",
    "    all_data[col] = all_data[col].astype(float)\n",
    "\n",
    "# === Indicateurs techniques ===\n",
    "print(\"‚úÖ Calcul des indicateurs techniques...\")\n",
    "\n",
    "close_series = all_data['close']\n",
    "high_series = all_data['high']\n",
    "low_series = all_data['low']\n",
    "\n",
    "all_data['rsi'] = ta.momentum.RSIIndicator(close_series, window=10).rsi()\n",
    "all_data['ema_9'] = close_series.ewm(span=9, adjust=False).mean()\n",
    "all_data['ema_21'] = close_series.ewm(span=21, adjust=False).mean()\n",
    "all_data['ema_distance'] = abs(all_data['ema_9'] - all_data['ema_21'])\n",
    "\n",
    "macd_calc = ta.trend.MACD(close_series)\n",
    "all_data['macd_line'] = macd_calc.macd()\n",
    "\n",
    "atr_indicator = ta.volatility.AverageTrueRange(high_series, low_series, close_series, window=14)\n",
    "all_data['atr'] = atr_indicator.average_true_range()\n",
    "\n",
    "all_data['volatility_close_std'] = close_series.rolling(window=10).std()\n",
    "all_data['ema_9_slope'] = all_data['ema_9'].diff(3)\n",
    "all_data['ema_21_slope'] = all_data['ema_21'].diff(3)\n",
    "\n",
    "# ‚úÖ Nouvelle target : pr√©dire la CLOSE dans 12 heures\n",
    "print(f\"‚úÖ Calcul de la target future_close √† {future_horizon} bougies...\")\n",
    "all_data['future_close'] = all_data['close'].shift(-future_horizon)\n",
    "\n",
    "# Nettoyage final\n",
    "all_data = all_data.dropna()\n",
    "\n",
    "print(all_data[['datetime', 'close', 'future_close']].head())\n",
    "\n",
    "# ‚úÖ Sauvegarde CSV\n",
    "all_data.to_csv('gold_features_hourly_future_close.csv', index=False)\n",
    "print(\"‚úÖ Donn√©es sauvegard√©es dans gold_features_hourly_future_close.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9d62df-6415-4175-b6c5-a17ec6752ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es\n",
      "              datetime     open     high      low    close        rsi  \\\n",
      "0  2025-05-01 02:05:00  3240.60  3242.61  3239.08  3239.30  36.037100   \n",
      "1  2025-05-01 02:10:00  3239.54  3240.29  3235.00  3240.29  38.445588   \n",
      "2  2025-05-01 02:15:00  3240.17  3246.89  3240.17  3245.06  48.772296   \n",
      "3  2025-05-01 02:20:00  3244.70  3250.03  3241.19  3250.03  57.103697   \n",
      "4  2025-05-01 02:25:00  3250.05  3251.29  3245.00  3246.39  50.429483   \n",
      "\n",
      "         ema_9       ema_21  ema_distance  macd_line       atr  \\\n",
      "0  3241.892523  3247.294002      5.401479  -6.370322  6.712800   \n",
      "1  3241.572019  3246.657275      5.085256  -6.124599  6.611171   \n",
      "2  3242.269615  3246.512068      4.242453  -5.481772  6.618945   \n",
      "3  3243.821692  3246.831880      3.010188  -4.519195  6.777591   \n",
      "4  3244.335354  3246.791709      2.456356  -4.003909  6.742763   \n",
      "\n",
      "   volatility_close_std  ema_9_slope  ema_21_slope  future_close  \n",
      "0              4.282865    -2.244749     -2.573215       3237.26  \n",
      "1              4.252431    -1.483799     -2.197468       3231.90  \n",
      "2              3.782719    -0.271039     -1.581335       3235.39  \n",
      "3              4.325824     1.929169     -0.462122       3232.74  \n",
      "4              3.955748     2.763335      0.134434       3233.19  \n",
      "‚úÖ Split termin√©\n",
      "‚úÖ Mod√®le entra√Æn√©\n",
      "\n",
      "‚úÖ Metrics:\n",
      " - MSE : 38.7900\n",
      " - RMSE: 6.2282\n",
      " - R2  : 0.9896\n",
      "‚úÖ Mod√®le sauvegard√© sous gold_future_close_regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# === 1Ô∏è‚É£ Chargement des donn√©es ===\n",
    "df = pd.read_csv('gold_features_hourly_future_close.csv')\n",
    "print(\"‚úÖ Donn√©es charg√©es\")\n",
    "print(df.head())\n",
    "\n",
    "# === 2Ô∏è‚É£ S√©lection des features ===\n",
    "features = [\n",
    "    'rsi',\n",
    "    'ema_9', 'ema_21', 'ema_distance',\n",
    "    'macd_line',\n",
    "    'atr',\n",
    "    'volatility_close_std',\n",
    "    'ema_9_slope', 'ema_21_slope'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['future_close']\n",
    "\n",
    "# === 3Ô∏è‚É£ Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"‚úÖ Split termin√©\")\n",
    "\n",
    "# === 4Ô∏è‚É£ Entra√Ænement ===\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Mod√®le entra√Æn√©\")\n",
    "\n",
    "# === 5Ô∏è‚É£ √âvaluation ===\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n‚úÖ Metrics:\")\n",
    "print(f\" - MSE : {mse:.4f}\")\n",
    "print(f\" - RMSE: {rmse:.4f}\")\n",
    "print(f\" - R2  : {r2:.4f}\")\n",
    "\n",
    "# === 6Ô∏è‚É£ Sauvegarde du mod√®le\n",
    "with open('gold_future_close_regressor.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"‚úÖ Mod√®le sauvegard√© sous gold_future_close_regressor.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5ba86-a8bf-4b9f-b3cc-bb0078ca4216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
